{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Enhanced Model Steps\n",
        "1. Load the Dataset\n",
        "2. Upload News Data to Vector Store\n",
        "3. Create an Assistant\n",
        "4. Get User History\n",
        "5. Recommend News based on user history"
      ],
      "metadata": {
        "id": "no1wD7wsIyxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Dataset"
      ],
      "metadata": {
        "id": "weGrSG_-AIOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks/\n",
        "file_path = \"behaviors_test.tsv\"\n",
        "\n",
        "# Read the raw data line by line\n",
        "with open(file_path, encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Parse each line\n",
        "parsed_data = []\n",
        "for line in lines:\n",
        "    fields = line.strip().split(\"\\t\")\n",
        "\n",
        "    while len(fields) < 5:\n",
        "        fields.append(\"\")  # Fill missing fields with empty strings\n",
        "\n",
        "    # Split the History and Impressions fields into lists\n",
        "    history = fields[3].split() if fields[3] else []\n",
        "    impressions = fields[4].split() if fields[4] else []\n",
        "    fields[3] = history\n",
        "    fields[4] = impressions\n",
        "\n",
        "    # Append the cleaned fields to the parsed data\n",
        "    parsed_data.append(fields)\n",
        "\n",
        "# Convert the parsed data into a DataFrame\n",
        "column_names = [\"Impression ID\", \"User ID\", \"Time\", \"History\", \"Impressions\"]\n",
        "behaviors_df = pd.DataFrame(parsed_data, columns=column_names)\n",
        "print(behaviors_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uno1WgZx4nWS",
        "outputId": "ff1502e0-59eb-4db8-a1f6-3f03663e030f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Colab Notebooks\n",
            "  Impression ID  User ID                 Time  \\\n",
            "0             5  U239687  2019-11-14 20:03:01   \n",
            "1            11  U108656  2019-11-14 06:51:18   \n",
            "2            12  U178651  2019-11-14 14:33:03   \n",
            "3            14   U95671  2019-11-14 20:28:43   \n",
            "4            16  U332817  2019-11-14 14:53:15   \n",
            "\n",
            "                                             History  \\\n",
            "0  [N65250, N122359, N71723, N53796, N41663, N414...   \n",
            "1  [N4833, N61319, N94639, N50163, N107002, N1120...   \n",
            "2  [N112192, N82348, N80126, N78767, N7553, N8736...   \n",
            "3  [N64593, N82779, N33216, N9321, N128643, N6449...   \n",
            "4  [N32197, N35797, N28326, N127821, N124453, N87...   \n",
            "\n",
            "                                         Impressions  \n",
            "0  [N76209-0, N48841-0, N67937-0, N62235-0, N6307...  \n",
            "1  [N95301-0, N79081-0, N103133-0, N80281-0, N703...  \n",
            "2  [N76189-0, N103133-0, N20871-0, N14675-0, N457...  \n",
            "3  [N62736-0, N52388-0, N16161-0, N127585-0, N885...  \n",
            "4                              [N118623-0, N68624-1]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "api_key = 'sk-svcacct-_u0YHRRp-oJiJUfO6yvWNlN6_ZVLrPPonlct008C6Vpe-22kS2E22bpFuk0EtyZRSNHTT3BlbkFJREMKmS2I1ICkr_LH5HBBGvlzwWBPkYOkkadNjNZE32vSsp3WxIxNGP2TRVnABaLX3mgA'\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "wV5Lj_VWAOTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_file_to_txt(file_path):\n",
        "    # Convert the tsv file to a txt file\n",
        "    txt_file_path = file_path.replace('.tsv', '.txt')\n",
        "    df = pd.read_csv(file_path, sep='\\t')\n",
        "    df.to_csv(txt_file_path, sep='\\t', index=False, header=False)\n",
        "\n",
        "    return txt_file_path"
      ],
      "metadata": {
        "id": "QGFXwZISAyZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Vector Store and Assistant"
      ],
      "metadata": {
        "id": "i3tmM_JwAsmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file_to_vector_store(file_path):\n",
        "    txt_file_path = encode_file_to_txt(file_path)\n",
        "\n",
        "    # Create the vector store\n",
        "    vector_store_id = client.beta.vector_stores.create(name=os.path.basename(txt_file_path)).id\n",
        "    with open(txt_file_path, \"rb\") as file_stream:\n",
        "        client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "            vector_store_id=vector_store_id, files=[file_stream]\n",
        "        )\n",
        "\n",
        "    os.remove(txt_file_path) # clean\n",
        "    return vector_store_id\n",
        "\n",
        "def create_assistant_with_vector_store(vector_store_id):\n",
        "    instructions = \"\"\"\n",
        "      Recommend 20 news articles based on the user's history:\n",
        "      1. Match subcategories of user's news.\n",
        "      2. Find similar content.\n",
        "      3. Prioritize based on engagement history.\n",
        "\n",
        "      Write the reason why you have chosen the recommendation\n",
        "      Do not give me any other information\n",
        "\n",
        "      Output format:\n",
        "      | News ID   | Title                        | Reason                         |\n",
        "      \"\"\"\n",
        "    assistant = client.beta.assistants.create(\n",
        "        name=\"news_recommendation_assistant\",\n",
        "        instructions=instructions,\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        tools=[{\"type\": \"file_search\"}],\n",
        "        tool_resources={\n",
        "            \"file_search\": {\"vector_store_ids\": [vector_store_id]}\n",
        "        }\n",
        "    )\n",
        "    return assistant.id\n"
      ],
      "metadata": {
        "id": "sMZBsI0BAtKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get User History"
      ],
      "metadata": {
        "id": "xg4Ik9CgBEGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_history(user_id, behaviors_df, news_df):\n",
        "    user_behaviors = behaviors_df[behaviors_df['User ID'] == user_id]\n",
        "\n",
        "    user_news_ids = []\n",
        "    for history in user_behaviors['History']:\n",
        "        if isinstance(history, list):\n",
        "            user_news_ids.extend(history)\n",
        "\n",
        "    user_history_df = news_df[news_df['News ID'].isin(user_news_ids)][['News ID', 'Title', 'Abstract']]\n",
        "\n",
        "    history_message = \"User history:\\n\"\n",
        "    for _, row in user_history_df.iterrows():\n",
        "        history_message += f\"News ID: {row['News ID']}, Title: {row['Title']}, Abstract: {row['Abstract']}\\n\"\n",
        "\n",
        "    return history_message"
      ],
      "metadata": {
        "id": "Yzz0QJ0HBA1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation System"
      ],
      "metadata": {
        "id": "3s7cTUPyCM1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_news_to_user(assistant_id, user_history_message):\n",
        "    try:\n",
        "        # Create a thread and send the user history message\n",
        "        thread = client.beta.threads.create()\n",
        "        client.beta.threads.messages.create(\n",
        "            thread_id=thread.id,\n",
        "            role=\"user\",\n",
        "            content=user_history_message\n",
        "        )\n",
        "\n",
        "        # Run the assistant\n",
        "        run = client.beta.threads.runs.create(\n",
        "            thread_id=thread.id,\n",
        "            assistant_id=assistant_id\n",
        "        )\n",
        "\n",
        "        # Wait for the run to complete\n",
        "        while run.status not in [\"completed\", \"failed\"]:\n",
        "            time.sleep(2)  # Introduce a 2-second delay between checks\n",
        "            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "            print(f\"Run status: {run.status}\")\n",
        "\n",
        "        if run.status == \"failed\":\n",
        "            print(f\"Run failed with error: {run.last_error}\")\n",
        "            return\n",
        "\n",
        "        print(\"Run completed successfully.\")\n",
        "\n",
        "        # Fetch all messages from the thread\n",
        "        messages = list(client.beta.threads.messages.list(thread_id=thread.id))\n",
        "        for i, message in enumerate(messages):\n",
        "            print(f\"Message {i} - Role: {message.role}, Content: {message.content}\")\n",
        "\n",
        "        # Extract the assistant's response\n",
        "        assistant_response = messages[0].content if messages else \"No messages found.\"\n",
        "\n",
        "        # extract text\n",
        "        if isinstance(assistant_response, list):\n",
        "            extracted_text = \"\".join(\n",
        "                block.text.value for block in assistant_response if hasattr(block, 'text')\n",
        "            )\n",
        "        else:\n",
        "            extracted_text = assistant_response\n",
        "\n",
        "        print(\"Assistant response:\", extracted_text)\n",
        "\n",
        "        # Save the response to a file\n",
        "        with open(\"recommended_news.txt\", \"w\") as f:\n",
        "            f.write(extracted_text)\n",
        "            print(\"Recommendations written to recommended_news.txt.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during recommendation: {e}\")"
      ],
      "metadata": {
        "id": "sU4N9n2RB-za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Execution"
      ],
      "metadata": {
        "id": "MHcyV4KECe6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # load the data\n",
        "    news_file_path = \"news.tsv\"\n",
        "    column_names = [\"Impression ID\", \"User ID\", \"Time\", \"History\", \"Impressions\"]\n",
        "    behaviors_df = pd.DataFrame(parsed_data, columns=column_names)\n",
        "    news_df = pd.read_csv(news_file_path, sep='\\t', header=None, names=[\n",
        "        \"News ID\", \"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"URL\",\n",
        "        \"Title Entities\", \"Abstract Entities\"\n",
        "    ])\n",
        "\n",
        "    # Step 2: Upload news data to vector store\n",
        "    vector_store_id = upload_file_to_vector_store(news_file_path)\n",
        "\n",
        "    # Step 3: Create assistant with vector store\n",
        "    assistant_id = create_assistant_with_vector_store(vector_store_id)\n",
        "    specific_user_id = 'U239687'\n",
        "\n",
        "    # Step 4: Retrieve and format user history\n",
        "    user_history_message = get_user_history(specific_user_id, behaviors_df, news_df)\n",
        "\n",
        "    # recommend\n",
        "    recommend_news_to_user(assistant_id, user_history_message)"
      ],
      "metadata": {
        "id": "e649mZj5CfnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(behaviors_df, recommendations):\n",
        "    \"\"\"\n",
        "    Evaluate the accuracy of the recommendations against ground truth.\n",
        "\n",
        "    Parameters:\n",
        "    - behaviors_df: DataFrame with user behaviors, including Impressions.\n",
        "    - recommendations: Dictionary with User ID as keys and list of recommended News IDs as values.\n",
        "\n",
        "    Returns:\n",
        "    - accuracy: Fraction of correctly recommended articles.\n",
        "    \"\"\"\n",
        "    total_relevant = 0\n",
        "    total_recommended = 0\n",
        "\n",
        "    for _, row in behaviors_df.iterrows():\n",
        "        user_id = row['User ID']\n",
        "        if user_id in recommendations:\n",
        "            # Extract ground truth clicked articles\n",
        "            impressions = row['Impressions']\n",
        "            ground_truth = [impression.split('-')[0] for impression in impressions if '-1' in impression]\n",
        "\n",
        "            # Extract system recommendations\n",
        "            recommended = recommendations[user_id]\n",
        "\n",
        "            # Count correct recommendations\n",
        "            correct_recommendations = len(set(recommended) & set(ground_truth))\n",
        "            total_relevant += len(ground_truth)\n",
        "            total_recommended += correct_recommendations\n",
        "\n",
        "    # Compute accuracy as the fraction of correctly recommended articles\n",
        "    accuracy = total_recommended / total_relevant if total_relevant > 0 else 0\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "6OuXvhc5PiKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate_accuracy(behaviors_df, recommendations)\n",
        "print(f\"Accuracy: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "ZdXfXPtwPm86",
        "outputId": "a6d5ec99-b4ef-49fc-f73f-6c39957ed58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'recommendations' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-d76ad27f2b24>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbehaviors_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {accuracy:.2%}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'recommendations' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}